{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da37f872",
   "metadata": {},
   "source": [
    "# NFT/Pre-NFT Inter-annotator Agreement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3fa6b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from itertools import combinations\n",
    "import cv2 as cv\n",
    "from tqdm.notebook import tqdm\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "from multiprocessing import Pool\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "\n",
    "from nft_helpers.utils import load_yaml, imread, imwrite\n",
    "from nft_helpers.plot import format_plot_edges\n",
    "from nft_helpers.box_and_contours import line_to_xys, xys_to_line\n",
    "from nft_helpers.roi_utils import read_roi_txt_file\n",
    "\n",
    "# Parameters\n",
    "cf = load_yaml()\n",
    "COLORS = [f'#{c}' for c in cf.colors]\n",
    "save_dir = join(cf.datadir, 'results/inter-annotator-agreement')\n",
    "makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec7f8e",
   "metadata": {},
   "source": [
    "## Annotation Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc47b72",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Bar plot of counts.\n",
    "df = read_csv('csvs/annotations.csv')\n",
    "df = df[(df.cohort == 'Annotated-Cohort') & (df.roi_group == 'ROIv2')]\n",
    "\n",
    "# Format the inter-annotator annotations for plotting as bars.\n",
    "ann_bar_df = []\n",
    "\n",
    "for annotator in df.annotator.unique():\n",
    "    ann_df = df[df.annotator == annotator]\n",
    "    \n",
    "    # Add the sum of all\n",
    "    ann_bar_df.append([annotator, 'Total', len(ann_df)])\n",
    "    \n",
    "    for ann_type, counts in ann_df.label.value_counts().items():\n",
    "        ann_bar_df.append([annotator, ann_type, counts])\n",
    "                \n",
    "ann_bar_df = DataFrame(\n",
    "    ann_bar_df, columns=['annotator', 'label', 'counts']\n",
    ").sort_values(by=['annotator', 'label'], ascending=[True, False])\n",
    "\n",
    "kwargs = {'edgecolor': 'k', 'lw': 3}\n",
    "colors = [COLORS[2], COLORS[1], COLORS[0]]\n",
    "ax = sns.barplot(data=ann_bar_df, x='annotator', y='counts', hue='label', \n",
    "                 palette=colors, hue_order=['Total', 'iNFT', 'Pre-NFT'],\n",
    "                 **kwargs)\n",
    "for i, bars in enumerate(ax.containers):\n",
    "    for bar in bars:\n",
    "        bar.set_hatch(cf.hatches[2-i])\n",
    "        \n",
    "plt.legend(bbox_to_anchor=(1.30, 1))\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='16') \n",
    "\n",
    "ax = format_plot_edges(ax)\n",
    "ax.tick_params(axis='both', which='both', direction='out', length=10, width=3)\n",
    "plt.xticks(rotation=90, fontsize=18)\n",
    "plt.xlabel(None)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.ylabel('Number of Annotations', fontsize=18)\n",
    "plt.legend(ncol=3, fontsize=14, bbox_to_anchor=(0.5, 1.10), loc='upper center')\n",
    "# plt.title('Annotations for Inter-annotator\\nAgreement Analysis', fontsize=18)\n",
    "plt.savefig(join(save_dir, 'annotation-counts.png'), bbox_inches='tight', \n",
    "            dpi=300)\n",
    "plt.show()\n",
    "\n",
    "ann_bar_df.to_csv(join(save_dir, 'annotation-counts.csv'), index=False)\n",
    "display(ann_bar_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3912c7",
   "metadata": {},
   "source": [
    "## Cohen's Kappas\n",
    "For each annotator create 30 ROI masks (1 per label for 15 ROIs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11af11",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Compile annotations into a dataframe for easy comparison between annotators.\n",
    "anns = []\n",
    "\n",
    "df = read_csv('csvs/matching-annotations.csv')\n",
    "annotators = sorted(df.iloc[0].groups.split(';'))\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    labels = r.labels.split(';')\n",
    "    groups = r.groups.split(';')\n",
    "    labels = {ann: lb for lb, ann in zip(labels, groups)}\n",
    "    \n",
    "    box = (line_to_xys(r.box_coords) - [r.roi_im_left, r.roi_im_top]).astype(int)\n",
    "    x1, y1 = np.min(box, axis=0)\n",
    "    x2, y2 = np.max(box, axis=0)\n",
    "    \n",
    "    row = [\n",
    "        r.wsi_name, r.region, r.roi_im_path, r.roi_im_left, r.roi_im_top,\n",
    "        r.roi_im_right - r.roi_im_left, r.roi_im_bottom - r.roi_im_top,\n",
    "        xys_to_line(line_to_xys(r.roi_corners) - [r.roi_im_left, r.roi_im_top]),\n",
    "        (x1, y1), (x2, y2),\n",
    "    ]\n",
    "    \n",
    "    for ann in annotators:\n",
    "        label = labels[ann]\n",
    "        \n",
    "        if label == 'iNFT':\n",
    "            row.append(2)\n",
    "        elif label == 'Pre-NFT':\n",
    "            row.append(1)\n",
    "        else:\n",
    "            row.append(0)\n",
    "        \n",
    "    anns.append(row)\n",
    "    \n",
    "anns = DataFrame(\n",
    "    anns, \n",
    "    columns=['wsi_name', 'region', 'roi_fp', 'roi_x1', 'roi_y1', 'roi_w', \n",
    "             'roi_h', 'roi_corners', 'pt1', 'pt2'] + annotators\n",
    ")\n",
    "display(anns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a741695",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix between pair of annotators.\n",
    "cm_dir = join(save_dir, 'cms')\n",
    "makedirs(cm_dir, exist_ok=True)\n",
    "labels = ('Background', 'Pre-NFT', 'iNFT')\n",
    "\n",
    "for pair in combinations(annotators, 2):\n",
    "    # Remove annotations that both these pairs labeled as background.\n",
    "    pair_df = anns[list(pair)]\n",
    "    pair_df = pair_df[\n",
    "        (pair_df[pair[0]] != 0) | (pair_df[pair[1]] != 0)\n",
    "    ]\n",
    "    \n",
    "    # Calculate the confusion matrix.\n",
    "    cm = confusion_matrix(pair_df[pair[0]], pair_df[pair[1]])\n",
    "    ncm = confusion_matrix(pair_df[pair[0]], pair_df[pair[1]], normalize='all')\n",
    "    # Plot the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            s = '' if i == j == 0 else cm[i, j]\n",
    "            ax.text(x=j, y=i,s=s, va='center', ha='center', size=18, \n",
    "                    color='k', weight='bold')\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.xticks(np.arange(0, 3), labels, fontsize=18)\n",
    "    plt.yticks(np.arange(0, 3), labels, fontsize=18)\n",
    "    plt.ylabel(pair[0], fontsize=18)\n",
    "    plt.xlabel(pair[1], fontsize=18)\n",
    "    plt.title('Confusion Matrix', fontsize=18)\n",
    "    plt.savefig(join(cm_dir, f'{pair[0]}-{pair[1]}-cm.png'), bbox_inches='tight', \n",
    "                dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2a95c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Cohen's kappa for annotation masks (parallel processing)\n",
    "roi_kappas = []\n",
    "labels = ['Pre-NFT', 'iNFT']\n",
    "pairs = list(combinations(annotators, 2))\n",
    "wsi_names = anns.wsi_name.unique()\n",
    "resize_factor = 0.5\n",
    "\n",
    "# For each WSI.\n",
    "params = []\n",
    "\n",
    "for n, wsi_name in enumerate(wsi_names):\n",
    "    for pair in pairs:\n",
    "        pair = sorted(list(pair))\n",
    "        params.append([wsi_name, pair[0], pair[1]])\n",
    "\n",
    "        \n",
    "def masks_cohens_kappa(wsi_name: str, annotator1: str, annotator2: str):\n",
    "    \"\"\"Calculate the Cohen's kappa between two masks for annotators.\n",
    "    \n",
    "    Args:\n",
    "        wsi_name: WSI name => unique ROI since only one ROI per WSI.\n",
    "        annotator1: Annotator 1.\n",
    "        annotator2: Annotator 2.\n",
    "        \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    roi_df = anns[anns.wsi_name == wsi_name]\n",
    "    \n",
    "    # Create a binary mask of the ROI region\n",
    "    r = roi_df.iloc[0]\n",
    "    roi_mask = np.zeros((r.roi_h, r.roi_w), dtype=np.uint8)\n",
    "    roi_mask = cv.drawContours(roi_mask, [line_to_xys(r.roi_corners)], -1, 255, \n",
    "                               cv.FILLED)\n",
    "    \n",
    "    # resize for quicker computations\n",
    "    roi_mask = cv.resize(roi_mask, None, fx=resize_factor, fy=resize_factor\n",
    "                        ).flatten()\n",
    "    \n",
    "    # Loop through each class\n",
    "    for label in [1, 2]:\n",
    "        # Create a label mask for this label for each annotator.\n",
    "        df = roi_df[roi_df[annotator1] == label]\n",
    "        mask1 = np.zeros((r.roi_h, r.roi_w), dtype=np.uint8)\n",
    "            \n",
    "        for _, r in df.iterrows():\n",
    "            mask1 = cv.rectangle(mask1, r.pt1, r.pt2, 1, cv.FILLED)\n",
    "                \n",
    "        # Resize and filter by the pixels inside the ROI.\n",
    "        mask1 = cv.resize(mask1, None, fx=resize_factor, fy=resize_factor\n",
    "                         ).flatten()[roi_mask == 255]\n",
    "        \n",
    "        df = roi_df[roi_df[annotator2] == label]\n",
    "        mask2 = np.zeros((r.roi_h, r.roi_w), dtype=np.uint8)\n",
    "            \n",
    "        for _, r in df.iterrows():\n",
    "            mask2 = cv.rectangle(mask2, r.pt1, r.pt2, 1, cv.FILLED)\n",
    "                \n",
    "        # Resize and filter by the pixels inside the ROI.\n",
    "        mask2 = cv.resize(mask2, None, fx=resize_factor, fy=resize_factor\n",
    "                         ).flatten()[roi_mask == 255]\n",
    "        \n",
    "        # Cohen's kappa\n",
    "        if np.count_nonzero(mask1) + np.count_nonzero(mask2):\n",
    "            k = cohen_kappa_score(mask1, mask2)\n",
    "        else:\n",
    "            # Kappa does not exist when both masks are all 0s  or all 1s. This\n",
    "            # is perfect agreement.\n",
    "            k = 1.\n",
    "                              \n",
    "        data.append([f'{annotator1}-{annotator2}', annotator1, annotator2, \n",
    "                     label-1, wsi_name, k])\n",
    "        \n",
    "    return data\n",
    "        \n",
    "    \n",
    "with Pool(20) as pool:\n",
    "    jobs = [pool.apply_async(func=masks_cohens_kappa, args=(p[0], p[1], p[2])) \n",
    "            for p in params]\n",
    "        \n",
    "    roi_df = []\n",
    "    \n",
    "    for job in tqdm(jobs):\n",
    "        roi_df.extend(job.get())\n",
    "    \n",
    "roi_df = DataFrame(roi_df, columns=['key', 'annotator1', 'annotator2', 'label',\n",
    "                                    'wsi_name', 'k'])\n",
    "roi_df.to_csv(join(save_dir, 'cohens-kappas.csv'), index=False)\n",
    "roi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec087ac",
   "metadata": {},
   "source": [
    "## Heatmaps of Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ab24c",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot heatmap of pair kappas between anntotation masks.\n",
    "def plot_tri_heatmap(data: np.array, labels: list, figsize: (int, int) = (7,7), \n",
    "                     title: str = None, save_fp: str = None, **kwargs: dict\n",
    "                    ) -> np.array:\n",
    "    \"\"\"Create a correlation heatmap from an array, only plotting the bottom half\n",
    "    triangle of the heatmap. \n",
    "    \n",
    "    Args:\n",
    "        data: Data to plot, the data is assumed to be symetrical and only the \n",
    "            bottom left triangle of the heatmap will be shown.\n",
    "        labels: Labels on both axis, ordered from top to bottom and left to \n",
    "            right.\n",
    "        figsize: (width, height) of figure.\n",
    "        title: Title of figure.\n",
    "        save_fp: Filepath to save figure to.\n",
    "        kwargs: Keyword arguments to pass to seaborn.heatmap()\n",
    "       \n",
    "    Returns:\n",
    "        The input data array.\n",
    "        \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    mask = np.triu(np.ones_like(data), k=1)\n",
    "    ax = sns.heatmap(data, annot=True, mask=mask, xticklabels=labels, \n",
    "                     yticklabels=labels, ax=ax, **kwargs)\n",
    "    ax.set_xticks(ax.get_xticks(), labels, size=16)\n",
    "    ax.set_yticks(ax.get_yticks(), labels, size=16, rotation=360)\n",
    "    ax.set_facecolor('k')\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=18, weight='bold')\n",
    "        \n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=16)\n",
    "        \n",
    "    return ax\n",
    "\n",
    "\n",
    "# Labels\n",
    "roi_df = read_csv('/workspace/data/results/inter-annotator-agreement/cohens-kappas.csv')\n",
    "\n",
    "annotators = set(roi_df.annotator1.unique())\n",
    "annotators.update(set(roi_df.annotator2.unique()))\n",
    "annotators = sorted(list(annotators))\n",
    "\n",
    "results = \"Average Cohen's Kappa for Annotations\\n\"\n",
    "results += '-' * (len(results)-1) + '\\n\\n'\n",
    "\n",
    "for label in [0, 1]:\n",
    "    kappa_hm = np.zeros((len(annotators), len(annotators)))\n",
    "    \n",
    "    expert_expert = {}\n",
    "    novice_novice = {}\n",
    "    expert_novice = {}\n",
    "    \n",
    "    for i, ann1 in enumerate(annotators):\n",
    "        for j, ann2 in enumerate(annotators):\n",
    "            if ann1 == ann2:\n",
    "                kappa_hm[i, j] = 1\n",
    "            else:\n",
    "                kappa_hm[i, j] = 0\n",
    "                anns = sorted([ann1, ann2])\n",
    "                key = f'{anns[0]}-{anns[1]}'\n",
    "                \n",
    "                k = roi_df[\n",
    "                    (roi_df.key == key) & (roi_df.label == label)\n",
    "                ].k.mean()\n",
    "                \n",
    "                if re.search('expert\\d-expert\\d', key) and key not in expert_expert:\n",
    "                    expert_expert[key] = k\n",
    "                elif re.search('expert\\d-novice\\d', key) and key not in expert_novice:\n",
    "                    expert_novice[key] = k\n",
    "                elif re.search('novice\\d-novice\\d', key) and key not in novice_novice:\n",
    "                    novice_novice[key] = k\n",
    "\n",
    "                kappa_hm[i, j] = k\n",
    "                                \n",
    "    kwargs = {'cmap': 'viridis', 'annot_kws': {\"size\":16}, \n",
    "              'linecolor': 'w', 'linewidths': 0}\n",
    "    \n",
    "    # Calculate the average and standard deviation of the pair kappas.\n",
    "    mask = np.triu(np.ones_like(kappa_hm))\n",
    "    kappas = kappa_hm[mask == 0]\n",
    "\n",
    "    ax = plot_tri_heatmap(\n",
    "        kappa_hm, \n",
    "        ['E1', 'E2', 'E3', 'E4', 'E5', 'N1', 'N2', 'N3', 'N4'], \n",
    "        figsize=(10,10), \n",
    "        title=f\"{cf.labels[label]} ({np.mean(kappas):.2f} \" + u\"\\u00B1\" + \\\n",
    "              f' {np.std(kappas):.2f})',\n",
    "        **kwargs\n",
    "    )\n",
    "    plt.savefig(join(save_dir, f'{cf.labels[label]}-hm.png'), \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    expert_expert = list(expert_expert.values())\n",
    "    novice_novice = list(novice_novice.values())\n",
    "    expert_novice = list(expert_novice.values())\n",
    "    all_pairs = expert_expert + novice_novice + expert_novice\n",
    "\n",
    "    results += f'{cf.labels[label]}:\\n'\n",
    "    results += f'   - Expert vs Expert: {np.mean(expert_expert):.2f} ' + \\\n",
    "               u\"\\u00B1\" + f' {np.std(expert_expert):.2f}\\n'\n",
    "    results += f'   - Expert vs Novice: {np.mean(expert_novice):.2f} ' + \\\n",
    "               u\"\\u00B1\" + f' {np.std(expert_novice):.2f}\\n'\n",
    "    results += f'   - Novice vs Novice: {np.mean(novice_novice):.2f} ' + \\\n",
    "               u\"\\u00B1\" + f' {np.std(novice_novice):.2f}\\n'\n",
    "    results += f'   - All pairs: {np.mean(all_pairs):.2f} ' + \\\n",
    "               u\"\\u00B1\" + f' {np.std(all_pairs):.2f}\\n\\n'\n",
    "    \n",
    "print(results.strip())\n",
    "\n",
    "with open(join(save_dir, 'results.txt'), 'w') as fh:\n",
    "    fh.write(results.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb2bf1",
   "metadata": {},
   "source": [
    "## Supplementary Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faef6459",
   "metadata": {},
   "source": [
    "### Point annotations to Class Binary Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b21bd5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get an ROI and draw the point annotations.\n",
    "rois_df = read_csv('csvs/labeled-rois.csv')\n",
    "r = rois_df.iloc[0]\n",
    "\n",
    "# Read the RGB image of ROI.\n",
    "img = imread(r.roi_im_path)\n",
    "mask1 = np.zeros(img.shape, dtype=np.uint8)\n",
    "mask2 = np.zeros(img.shape, dtype=np.uint8)\n",
    "\n",
    "# Draw the point annotations.\n",
    "points = read_roi_txt_file(r.roi_labels)\n",
    "\n",
    "for pt in read_roi_txt_file(r.roi_labels):\n",
    "    lb, x1, y1, x2, y2 = pt\n",
    "    \n",
    "    xc, yc = int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
    "    \n",
    "    img = cv.circle(img, (xc, yc), 45, (255, 0, 0) if lb else (0, 0, 255), 10)\n",
    "    \n",
    "    if lb:\n",
    "        mask1 = cv.rectangle(mask1, (x1, y1), (x2, y2), (255, 0, 0), cv.FILLED)\n",
    "    else:\n",
    "        mask2 = cv.rectangle(mask2, (x1, y1), (x2, y2), (0, 0, 255), cv.FILLED)\n",
    "    \n",
    "plt.figure(figsize=(5,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.savefig(join(save_dir, f'sample-roi-with-points.png'), bbox_inches='tight',\n",
    "            dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(5,10))\n",
    "plt.imshow(mask1)\n",
    "plt.axis('off')\n",
    "plt.savefig(join(save_dir, f'sample-iNFT-label-mask.png'), bbox_inches='tight',\n",
    "            dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(5,10))\n",
    "plt.imshow(mask2)\n",
    "plt.axis('off')\n",
    "plt.savefig(join(save_dir, f'sample-Pre-NFT-label-mask.png'), \n",
    "            bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
