{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b378f8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9413641",
   "metadata": {},
   "source": [
    "# Model Assisted Labeling Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c65225a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from pandas import read_csv\n",
    "from colorama import Fore, Style\n",
    "from glob import glob\n",
    "from shutil import rmtree\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from geopandas import GeoDataFrame\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm\n",
    "from math import ceil\n",
    "\n",
    "from os import makedirs, remove\n",
    "from os.path import join, isfile, isdir\n",
    "\n",
    "from nft_helpers.utils import (\n",
    "    load_yaml, get_filename, im_to_txt_path, delete_file, imread, Timer\n",
    ")\n",
    "from nft_helpers import compile_model_results, update_roi_tile_labels\n",
    "from nft_helpers.yolov5 import predict\n",
    "from nft_helpers.yolov5.utils import (\n",
    "    read_yolo_label, non_max_suppression, remove_contained_boxes, draw_boxes\n",
    ")\n",
    "from nft_helpers.box_and_contours import corners_to_polygon, line_to_xys\n",
    "from nft_helpers.girder_dsa import login, get_annotations_documents\n",
    "\n",
    "from ipywidgets import (\n",
    "    interactive, HBox, VBox, HTML, Button, IntProgress, ToggleButtons, Text,\n",
    "    Layout\n",
    ")\n",
    "\n",
    "# Setup\n",
    "np.set_printoptions(suppress=True)\n",
    "cf = load_yaml()\n",
    "dataset_dir = join(cf.datadir, 'datasets/model-assisted-labeling')\n",
    "df_fp = join(dataset_dir, 'model-assisted-labeling.csv')\n",
    "tile_df = read_csv(join(dataset_dir, 'tiles.csv'))\n",
    "label_map = {lb: i for i, lb in enumerate(cf.labels)}\n",
    "\n",
    "# Specify the weights to start the model-assisted-worflow with.\n",
    "starting_weights = join(\n",
    "    cf.datadir,\n",
    "    'models/4-models-consensus-n2/4-models-consensus-n2/weights/best.pt'\n",
    ")\n",
    "models_dir = join(cf.datadir, 'models/model-assisted-labeling')\n",
    "makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Parameters of interest.\n",
    "device = None\n",
    "conf_thr = 0.25\n",
    "iou_thr = 0.4\n",
    "contained_thr = 0.7\n",
    "img_size = 1280\n",
    "\n",
    "# percent (as fraction) of ROIs to clean up in each iteration\n",
    "perc_per_iteration = 0.05##switch to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27943413",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login or email: jvizcar\n",
      "Password for jvizcar: ········\n"
     ]
    }
   ],
   "source": [
    "# Authenticate girder client.\n",
    "gc = login(join(cf.dsaURL, 'api/v1'), username=cf.user, password=cf.password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5301c47",
   "metadata": {},
   "source": [
    "## Step 1) Predict Labels + Select ROIs\n",
    "1. Choose latest model to predict on ROIs not yet manually checked.\n",
    "2. Merge predictions to update ROI labels (add average confidence of predictions)\n",
    "3. Identify next set of ROIs to clean up and push labels as DSA annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd96a56",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose latest model and predict.\n",
    "# Read or start the csv file.\n",
    "if isfile(df_fp):\n",
    "    # Read the file\n",
    "    df = read_csv(df_fp)\n",
    "else:\n",
    "    # Starting model assisted labeling.\n",
    "    df = read_csv(join(dataset_dir, 'rois.csv')).sort_values(by='fp')\n",
    "    \n",
    "    # Add new columns\n",
    "    df['iteration'] = [-1] * len(df)\n",
    "    df['checked'] = [False] * len(df)\n",
    "    df['mean_conf'] = [1.] * len(df)\n",
    "    df['labels_updated'] = [False] * len(df)\n",
    "    df['roi_index'] = list(range(1, len(df)+1))\n",
    "    df.to_csv(df_fp, index=False)\n",
    "    \n",
    "# Check if there is a model for the latest iteration.\n",
    "latest_iteration = df.iteration.max()\n",
    "\n",
    "if latest_iteration < 1:\n",
    "    # Starting iteration\n",
    "    weights = starting_weights\n",
    "    latest_iteration = 0\n",
    "else:\n",
    "    model_results = compile_model_results(\n",
    "        join(cf.datadir, 'models/model-assisted-labeling')\n",
    "    )\n",
    "    \n",
    "    model_results = model_results[\n",
    "        (model_results.model == f'iteration{latest_iteration}') & \\\n",
    "        (model_results.dataset == 'test-roi') & \\\n",
    "        (model_results.label == 'all')\n",
    "    ]\n",
    "    \n",
    "    if len(model_results) != 3:\n",
    "        raise Exception(\n",
    "            f'Models for current iteration ({latest_iteration}) not trained!'\n",
    "        )\n",
    "        \n",
    "    # Get the best model for this iteration.\n",
    "    model_results = model_results.sort_values(by='mAP50-95', ascending=False)\n",
    "    \n",
    "    weights = model_results.iloc[0].weights\n",
    "    \n",
    "# Clear the cache\n",
    "for cache_fp in glob(join(dataset_dir, 'texts/*.cache')):\n",
    "    delete_file(cache_fp)\n",
    "    \n",
    "# Now use the best weights to predict on all ROIs not of current iterations.\n",
    "N = len(df[df.iteration == -1])\n",
    "\n",
    "n = 1\n",
    "for i, r in df.iterrows():\n",
    "    if r.iteration != -1:\n",
    "        continue\n",
    "    \n",
    "    print(Fore.BLUE, Style.BRIGHT, f'Processing ROI {n} of {N}', \n",
    "          Style.RESET_ALL)\n",
    "    roi_dir = join(dataset_dir, 'tiles', get_filename(r.fp))\n",
    "    \n",
    "    # Delete the label directory.\n",
    "    if isdir(join(roi_dir, 'labels')):\n",
    "        rmtree(join(roi_dir, 'labels'))\n",
    "\n",
    "    predict(\n",
    "        join(roi_dir, 'images'),\n",
    "        roi_dir,\n",
    "        weights,\n",
    "        device=device,\n",
    "        conf_thr=conf_thr,\n",
    "        iou_thr=iou_thr,\n",
    "        im_size=img_size,\n",
    "    )\n",
    "\n",
    "    # Read predictions and merge to get ROI labels.\n",
    "    boxes_df = []\n",
    "    \n",
    "    for _, tile_r in tile_df[tile_df.roi_fp == r.fp].iterrows():\n",
    "        label_fp = im_to_txt_path(tile_r.fp)\n",
    "        \n",
    "        if isfile(label_fp):\n",
    "            labels = ''  # overwrite previous predictions as a label file.\n",
    "            \n",
    "            for box in read_yolo_label(label_fp):\n",
    "                label, xc, yc, bw, bh = box[:5]\n",
    "\n",
    "                labels += f'{label:.0f} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\\n'\n",
    "                \n",
    "                # Convert box.\n",
    "                xc, yc = (xc * img_size) + tile_r.x, (yc * img_size) + tile_r.y\n",
    "                bw, bh = bw * img_size, bh * img_size\n",
    "                \n",
    "                half_bw, half_bh = bw / 2, bh / 2\n",
    "                x1, y1 = int(xc - half_bw), int(yc - half_bh)\n",
    "                x2, y2 = int(xc + half_bw), int(yc + half_bh)\n",
    "                \n",
    "                boxes_df.append([\n",
    "                    int(label), x1, y1, x2, y2, box[5], \n",
    "                    corners_to_polygon(x1, y1, x2, y2)\n",
    "                ])\n",
    "            \n",
    "            with open(label_fp, 'w') as fh:\n",
    "                fh.write(labels.strip())\n",
    "         \n",
    "    roi_label_fp = im_to_txt_path(r.fp)\n",
    "    \n",
    "    # Delete label file if it exists.\n",
    "    delete_file(roi_label_fp)\n",
    "    \n",
    "    if len(boxes_df):\n",
    "        # Merge the boxes to create ROI label.\n",
    "        boxes_df = GeoDataFrame(\n",
    "            boxes_df, \n",
    "            columns=['label', 'x1', 'y1', 'x2', 'y2', 'conf', 'geometry']\n",
    "        )\n",
    "        \n",
    "        df.loc[i, 'mean_conf'] = boxes_df.conf.mean()\n",
    "        \n",
    "        labels = ''\n",
    "        \n",
    "        boxes_df = non_max_suppression(boxes_df, iou_thr)\n",
    "        boxes_df = remove_contained_boxes(boxes_df, contained_thr)\n",
    "        \n",
    "        for _, box_r in boxes_df.iterrows():\n",
    "            x1, y1, x2, y2 = box_r.x1, box_r.y1, box_r.x2, box_r.y2\n",
    "            \n",
    "            # Format back\n",
    "            x1, y1, x2, y2 = x1 / r.w, y1 / r.h, x2 / r.w, y2 / r.h\n",
    "            \n",
    "            xc, yc = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "            bw, bh = x2 - x1, y2 - y1\n",
    "            \n",
    "            labels += f'{box_r.label} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\\n'\n",
    "            \n",
    "            \n",
    "        # Save the new ROI label.\n",
    "        with open(roi_label_fp, 'w') as fh:\n",
    "            fh.write(labels.strip())\n",
    "    else:\n",
    "        df.loc[i, 'mean_conf'] = 1.\n",
    "        \n",
    "    n += 1\n",
    "    \n",
    "    clear_output()\n",
    "    \n",
    "# Assign the next set of ROIs for cleanup.\n",
    "df = df.sort_values(by=['iteration', 'mean_conf', 'fp']).reset_index(drop=True)\n",
    "num_per_iter = ceil(perc_per_iteration * len(df))\n",
    "new_iteration = latest_iteration + 1\n",
    "df.loc[:num_per_iter-1, 'iteration'] = new_iteration\n",
    "\n",
    "# Update the csv.\n",
    "df.to_csv(df_fp, index=False)\n",
    "\n",
    "# For selected ROIs push the annotations as DSA documents.\n",
    "print(Fore.BLUE, Style.BRIGHT, 'Pushing new annotations.', Style.RESET_ALL)\n",
    "current_df = df[df.iteration == new_iteration]\n",
    "for _, r in tqdm(current_df.iterrows(), total=len(current_df)):\n",
    "    doc_name = f'iteration{new_iteration}_ROI{r.roi_index}'\n",
    "    \n",
    "    label_fp = im_to_txt_path(r.fp)\n",
    "    \n",
    "    els = []\n",
    "    \n",
    "    if isfile(label_fp):\n",
    "        # Push boxes as annotations.\n",
    "        boxes = read_yolo_label(\n",
    "            label_fp, im_shape=(r.w, r.h), shift=(-r.x, -r.y)\n",
    "        )\n",
    "        \n",
    "        for box in boxes:\n",
    "            label, xc, yc, bw, bh = box[:5].astype(int)\n",
    "            \n",
    "            els.append({\n",
    "                'center': [int(xc), int(yc), 0],\n",
    "                'group': cf.labels[label],\n",
    "                'height': int(bh),\n",
    "                'width': int(bw),\n",
    "                'label': {'value': cf.labels[label]},\n",
    "                'lineColor': cf.label_colors[label],\n",
    "                'lineWidth': 3,\n",
    "                'type': 'rectangle'\n",
    "            })\n",
    "    \n",
    "    _ = gc.post(\n",
    "        f'/annotation?itemId={r.wsi_id}', \n",
    "        json={'name': doc_name, 'description': '', 'elements': els}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62b218",
   "metadata": {},
   "source": [
    "## Step 2) Manual Cleanup of ROIs\n",
    "Use interactive to clean up ROIs.\n",
    "* Clean them up in order.\n",
    "* Track which ROIs are cleaned.\n",
    "* Allow timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6815d3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m \u001b[1m All ROIs in current iteration checked, train new models. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Interactive: manually clean the next iteration of ROIs.\n",
    "def timer_func(bn):\n",
    "    \"\"\"Start timer / modify timer.\"\"\"\n",
    "    if bn.icon == 'solid play':\n",
    "        # Starting timer.\n",
    "        timer.start()\n",
    "        \n",
    "        bn.icon = 'solid stop'\n",
    "        bn.style.button_color = 'red'\n",
    "        timer_desc.value = '<h4>Timer running...</h4>'\n",
    "    else:\n",
    "        # Pausing timer.\n",
    "        timer.stop()\n",
    "        \n",
    "        bn.icon = 'solid play'\n",
    "        bn.style.button_color = 'green'\n",
    "        timer_desc.value = '<h4>Timer stoped / paused.</h4>'\n",
    "        \n",
    "        \n",
    "def next_roi(bn):\n",
    "    \"\"\"Go to next ROI.\"\"\"\n",
    "    df.loc[progress.value-1, 'checked'] = True\n",
    "    df.to_csv(df_fp, index=False)\n",
    "    \n",
    "    if progress.value == n:\n",
    "        if timer.running:\n",
    "            timer.stop()\n",
    "        \n",
    "        # Finished!\n",
    "        clear_output()\n",
    "        print(Fore.GREEN, Style.BRIGHT, 'Complete, time to train new models!', \n",
    "              Style.RESET_ALL)\n",
    "    else:\n",
    "        prev_bn.disabled = False\n",
    "        \n",
    "        # Start timer if it was off!\n",
    "        if timer_bn.icon == 'solid play':\n",
    "            timer_func(timer_bn)\n",
    "        \n",
    "        progress.value += 1\n",
    "        progress.description = f'ROI {progress.value} of {n}:'\n",
    "        \n",
    "        # Update HTMLs\n",
    "        r = df.iloc[progress.value - 1]\n",
    "        \n",
    "        dsa_url = join(\n",
    "            cf.dsaURL, \n",
    "            f'histomics#?image={r.wsi_id}&bounds={r.x}%2C{r.y}%2C{r.x+r.w}' + \\\n",
    "            f'%2C{r.y+r.h}%2C0'\n",
    "        )\n",
    "        pearce_url = 'https://pearcetm.github.io/osd-paperjs-annotation/demo/' + \\\n",
    "                     'yoloreviewer/app.html#dsa=https://computablebrain.emory' + \\\n",
    "                     f'.edu&image={r.wsi_id}&bounds={r.x}%2C{r.y}%2C{r.x+r.w}' + \\\n",
    "                     f'%2C{r.y+r.h}'\n",
    "        \n",
    "        roi_hyperlink.value = f'<h3>ROI {r.roi_index}:    </h3>'\n",
    "        hu_hyperlink.value = f'<h3><a href=\"{dsa_url}\" target=\"_blank\">' + \\\n",
    "                             'HistomicsUI</a></h3>'\n",
    "        p_hyperlink.value = f'<h3><a href=\"{pearce_url}\" style=\"color: #29e807\" target=\"_blank\">' + \\\n",
    "                           'Pearce App</a></h3>'\n",
    "        \n",
    "        # Change the button if this is the last.\n",
    "        if progress.value == n:\n",
    "            next_bn.description = 'Finish'\n",
    "            next_bn.icon = 'duotone flag checkered'\n",
    "            next_bn.style.button_color = '#00FF09'\n",
    "            \n",
    "            \n",
    "def prev_roi(bn):\n",
    "    \"\"\"Logic for previous ROI.\"\"\"\n",
    "    df.loc[progress.value-2, 'checked'] = False\n",
    "    df.to_csv(df_fp, index=False)\n",
    "    \n",
    "    progress.value -= 1\n",
    "    progress.description = f'ROI {progress.value} of {n}:'\n",
    "    \n",
    "    # Update HTMLs\n",
    "    r = df.iloc[progress.value - 1]\n",
    "\n",
    "    dsa_url = join(\n",
    "        cf.dsaURL, \n",
    "        f'histomics#?image={r.wsi_id}&bounds={r.x}%2C{r.y}%2C{r.x+r.w}' + \\\n",
    "        f'%2C{r.y+r.h}%2C0'\n",
    "    )\n",
    "    pearce_url = 'https://pearcetm.github.io/osd-paperjs-annotation/demo/' + \\\n",
    "                 'yoloreviewer/app.html#dsa=https://computablebrain.emory' + \\\n",
    "                 f'.edu&image={r.wsi_id}&bounds={r.x}%2C{r.y}%2C{r.x+r.w}' + \\\n",
    "                 f'%2C{r.y+r.h}'\n",
    "\n",
    "    roi_hyperlink.value = f'<h3>ROI {r.roi_index}:    </h3>'\n",
    "    hu_hyperlink.value = f'<h3><a href=\"{dsa_url}\" target=\"_blank\">' + \\\n",
    "                         'HistomicsUI</a></h3>'\n",
    "    p_hyperlink.value = f'<h3><a href=\"{pearce_url}\" style=\"color: #29e807\" target=\"_blank\">' + \\\n",
    "                       'Pearce App</a></h3>'\n",
    "    \n",
    "    if progress.value  == 1:\n",
    "        bn.disabled = True\n",
    "        \n",
    "    if next_bn.description == 'Finish':\n",
    "        next_bn.description = 'Next'\n",
    "        next_bn.style.button_color = '#88F78C'\n",
    "        next_bn.icon = 'forward'\n",
    "            \n",
    "\n",
    "# Read the csv.\n",
    "if not isfile(df_fp):\n",
    "    raise Exception('ROI csv file does not exist, please run the first cell.')\n",
    "    \n",
    "df = read_csv(df_fp)\n",
    "\n",
    "# Sort appropriately.\n",
    "df = df.sort_values(by=['iteration', 'mean_conf', 'fp'], \n",
    "                    ascending=[False, True, True]).reset_index(drop=True)\n",
    "\n",
    "iteration = df.iteration.max()\n",
    "\n",
    "indices = df[df.iteration == iteration].index\n",
    "n = len(indices)\n",
    "\n",
    "# current index\n",
    "index = df[(df.iteration == iteration) & (~df.checked)].index\n",
    "\n",
    "if len(index):\n",
    "    timer_dir = join(dataset_dir, 'timer-logs')\n",
    "    makedirs(timer_dir, exist_ok=True)\n",
    "    \n",
    "    timer = Timer(join(timer_dir, f'{iteration}.txt'))\n",
    "    \n",
    "    index = index[0]\n",
    "    \n",
    "    # Widgets\n",
    "    timer_desc = HTML(\n",
    "        value=f'<h4>Timer not started.</h4>', description=''\n",
    "    )\n",
    "    timer_bn = Button(\n",
    "        description='', style={'font_weight': 'bold'}, \n",
    "        icon='solid play'\n",
    "    )\n",
    "    timer_bn.style.button_color = 'green'\n",
    "    timer_bn.on_click(timer_func)\n",
    "    \n",
    "    progress = IntProgress(\n",
    "        value=index+1, min=1, max=len(indices),\n",
    "        description=f'ROI {index+1} of {n}:',\n",
    "        style= {'solid description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    next_bn = Button(description='Next', style={'font_weight': 'bold'},\n",
    "                     icon='forward')\n",
    "    next_bn.style.button_color = '#88F78C'\n",
    "    next_bn.on_click(next_roi)\n",
    "    \n",
    "    # If you are at the last ROI then set the button appropriately.\n",
    "    if index == n-1:\n",
    "        next_bn.description = 'Finish'\n",
    "        next_bn.icon = 'duotone flag checkered'\n",
    "        next_bn.style.button_color = '#00FF09'\n",
    "    \n",
    "    prev_bn = Button(description='Previous', style={'font_weight': 'bold'},\n",
    "                     icon='backward')\n",
    "    prev_bn.style.button_color = '#FF9100'\n",
    "    prev_bn.on_click(prev_roi)\n",
    "    \n",
    "    if index == 0:\n",
    "        prev_bn.disabled = True\n",
    "        \n",
    "    r = df.iloc[index]\n",
    "    dsa_url = join(cf.dsaURL, f'histomics#?image={r.wsi_id}&bounds={r.x}%2C{r.y}'\n",
    "               f'%2C{r.x+r.w}%2C{r.y+r.h}%2C0')\n",
    "    \n",
    "    # URL to pearce app.\n",
    "    pearce_url = 'https://pearcetm.github.io/osd-paperjs-annotation/demo/' + \\\n",
    "                 'yoloreviewer/app.html#dsa=https://computablebrain.emory' + \\\n",
    "                 f'.edu&image={r.wsi_id}&bounds={r.x}%2C{r.y}%2C{r.x+r.w}' + \\\n",
    "                 f'%2C{r.y+r.h}'\n",
    "               \n",
    "    roi_hyperlink = HTML(\n",
    "        value=f'<h3>ROI {r.roi_index}:    </h3>', description='')\n",
    "    \n",
    "    hu_hyperlink = HTML(\n",
    "        value=f'<h3><a href=\"{dsa_url}\" target=\"_blank\">'\n",
    "                    'HistomicsUI</a></h3>', description='')\n",
    "    p_hyperlink = HTML(\n",
    "        value=f'<h3><a href=\"{pearce_url}\" style=\"color: #29e807\" target=\"_blank\">'\n",
    "                    'Pearce App</a></h3>', description='')\n",
    "    \n",
    "    ui = VBox([\n",
    "        HBox([timer_bn, timer_desc]),\n",
    "        progress,\n",
    "        HBox([prev_bn, next_bn]),\n",
    "        HBox([roi_hyperlink, hu_hyperlink, p_hyperlink])\n",
    "    ])\n",
    "    display(ui)\n",
    "else:\n",
    "    print(\n",
    "        Fore.GREEN, Style.BRIGHT, \n",
    "        'All ROIs in current iteration checked, train new models.',\n",
    "        Style.RESET_ALL\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca330f5",
   "metadata": {},
   "source": [
    "## Step 3) Update Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba8782",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get ROI labels from DSA and update tile labels.\n",
    "df = read_csv(df_fp)\n",
    "tile_df = read_csv(join(dataset_dir, 'tiles.csv'))\n",
    "\n",
    "iteration = df.iteration.max()\n",
    "\n",
    "if not all(df[df.iteration == iteration].checked):\n",
    "    raise Exception('Not all ROIs have been checked, please use interactive.')\n",
    "    \n",
    "df_iteration = df[df.iteration == iteration]\n",
    "\n",
    "print(Fore.BLUE, Style.BRIGHT, 'Updating ROI & Tile Labels', Style.RESET_ALL)\n",
    "\n",
    "for i, r in tqdm(df_iteration.iterrows(), total=len(df_iteration)):\n",
    "    # Get annotation document.\n",
    "    doc_name = f'iteration{iteration}_ROI{r.roi_index}'\n",
    "    \n",
    "    labels = ''\n",
    "    \n",
    "    for doc in get_annotations_documents(gc, r.wsi_id, docs=[doc_name]):\n",
    "        for el in doc['annotation']['elements']:\n",
    "            if el['group'] in label_map:\n",
    "                xc, yc = el['center'][:2]\n",
    "                xc -= r.x\n",
    "                yc -= r.y\n",
    "                bw, bh = el['width'] / r.w, el['height'] / r.h\n",
    "                \n",
    "                xc /= r.w\n",
    "                yc /= r.h\n",
    "                \n",
    "                labels += f\"{label_map[el['group']]} {xc:.6f} {yc:.6f} \" + \\\n",
    "                          f'{bw:.6f} {bh:.6f}\\n'\n",
    "    \n",
    "    label_fp = im_to_txt_path(r.fp)\n",
    "    \n",
    "    if len(labels):\n",
    "        with open(label_fp, 'w') as fh:\n",
    "            fh.write(labels.strip())\n",
    "    elif isfile(label_fp):\n",
    "        # No more labels delete\n",
    "        delete_file(label_fp)\n",
    "        \n",
    "    update_roi_tile_labels(tile_df[tile_df.roi_fp == r.fp], label_fp, \n",
    "                           (r.w, r.h), 0.5)\n",
    "    \n",
    "    df.loc[i, 'labels_updated'] = True\n",
    "        \n",
    "df.to_csv(df_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a846aa7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for log_fp in sorted(list(glob(join(dataset_dir, 'timer-logs/*.txt')))):\n",
    "    with open(log_fp, 'r') as fh:\n",
    "        time = 0\n",
    "\n",
    "        for line in fh.readlines():\n",
    "            time += int(line.strip())\n",
    "\n",
    "    minutes = int(time / 60)\n",
    "    hours = int(minutes / 60)\n",
    "    minutes = minutes % 60\n",
    "    iteration = get_filename(log_fp)\n",
    "\n",
    "    print(f'(Iteration {iteration}) Time taken: {hours} hour(s) & {minutes}'\n",
    "          ' minutes.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
